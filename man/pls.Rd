% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/plsFuncs.R
\name{pls}
\alias{pls}
\title{Computes regularized preconditioned least squares}
\usage{
pls(X, Y, compression, q, rand, regTerm, SameQ, lam, divergencedf = FALSE,
  ...)
}
\arguments{
\item{X}{the design matrix}

\item{Y}{the response vector}

\item{compression}{either full compression ('qxqy') or partial
compression ('qxy') or 'linComb' or 'convexComb'}

\item{q}{columns in the compression matrix}

\item{rand}{random number generator to build the compression matrix}

\item{regTerm}{determines how the regularization is imposed}

\item{SameQ}{use the same Q matirx in both parts of the linear combination}

\item{lam}{the amount of regularization}

\item{divergencedf}{If true, the Stein approximator to the degrees of
freedom is calculated and returned.}

\item{...}{optional arguments to the random number generator}
}
\value{
A list with components:
 \describe{
   \item{\code{bhat}}{the vector of estimated coefficients}
   \item{\code{df}}{The degrees of freedom of the procedure. If full or partial
    compression, this is the trace of the smoothing matrix. For the other cases,
    the procedure is not a linear smoother, but rather a weighted sum of
    two linear smoothers. In that case, this value is simply the weighted sum
    of the two linear procedures. Note that this likely underestimates the
    true degrees of freedom.}
   \item{\code{hatmat}}{If we use full or partial compression, the procedure
    is linear in the response and the smoothing matrix is returned here.}
   \item{\code{divdf}}{If we use the same Q matrix for both procedures and use
    lambda times the identity as a regularizer, then Stein's Lemma gives an
    alternative degrees-of-freedom approximation. If requested,
    (\code{divergencedf==TRUE}), this estimate is also returned.}
}
#@export
}
\description{
This function generalized \code{\link{plsBasic}} by combining full and partial
compression if desired.
}
\details{
This function implements four different compression algorithms with
different regularization versions. In addition to full and partial compression
as in \code{\link{plsBasic}}, it also combines these two in two ways.

The first method, 'linComb', estimates both full and partial compression, calculates their predictions, and then generates a weighted combination of the two. The weights are given as the solution to
\deqn{min ||[Yhat_{qxqy}, Yhat_{qxy}]a - Y||.}
This method can use the same Q or different Q matrices and any type of regularization.

The second method, 'convexComb', is similar, though it first finds the fully and partially compressed versions using the same Q with the identity regularization. It then finds a convex combination of the fitted values. That is, it also solves \deqn{min ||[Yhat_{qxqy}, Yhat_{qxy}]a - Y||} subject to the constraint that \eqn{a=[a1, 1-a1]} with \eqn{a1 \in [0,1]}.
}
\examples{
n = 100
p = 5
q = 50
X = generateX(n, diag(1,p), 'rnorm')
Y = generateY(X, p:1, 'rnorm')
bhat = pls(X, Y, 'linComb', q=q, regTerm='Ident', lam=1)
}
\seealso{
plsBasic
}
